{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85587291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Documents\\Coding\\Python\\Chatbot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea15fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3356db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_store = FAISS.from_texts([\"\"], embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9acdad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import MultiQueryRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# Suppose you have your base vectorstore retriever\n",
    "retriever = memory_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 20, \"fetch_k\": 50, \"lambda_mult\": 0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b7d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = VectorStoreRetrieverMemory(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9410640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(query: str):\n",
    "    history_docs = memory.load_memory_variables({'input':query})\n",
    "    return history_docs.get(\"history\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b62cbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a concise and knowledgeable AI assistant.\n",
    "Use the past conversation if it helps answer the query, otherwise ignore it.\n",
    "\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "User Query:\n",
    "{query}\n",
    "\n",
    "Your answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5a82238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'query'], input_types={}, partial_variables={}, template='\\nYou are a concise and knowledgeable AI assistant.\\nUse the past conversation if it helps answer the query, otherwise ignore it.\\n\\nConversation history:\\n{history}\\n\\nUser Query:\\n{query}\\n\\nYour answer:\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"history\", \"query\"]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f867d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af9941e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'history': RunnableLambda(get_history),\n",
    "    'query': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f330e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain = parallel_chain | prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str):\n",
    "    answer = main_chain.invoke(query)\n",
    "    memory.save_context({\"input\": query}, {\"output\": answer})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60ccbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"Explain the concept of diffusion tarnsformers.\"\n",
    "query2 = \"Compare its architecture from the standard one.\"\n",
    "query3 = \"Explain it in more detail.\"\n",
    "query4 = \"Generate a detailed report on AI revolution in India.\"\n",
    "query5 = \"Let's continue the previous conversation we were having.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "865981e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_docs = memory_store.similarity_search(\"\", k=100)\n",
    "len(hist_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diffusion transformers are a type of deep learning model that combines the strengths of diffusion models and transformer architectures. \\n\\nDiffusion models are a class of generative models that iteratively refine the input data by adding noise and then removing it, learning the reverse process to generate new data samples. \\n\\nTransformer models, on the other hand, are primarily used for natural language processing and are known for their ability to handle sequential data and capture long-range dependencies.\\n\\nBy integrating these two concepts, diffusion transformers aim to leverage the power of diffusion models for generative tasks, such as image synthesis, while utilizing the strengths of transformer models in handling complex sequential data.\\n\\nThe key benefits of diffusion transformers include:\\n\\n1. **Improved generation quality**: By iteratively refining the input data, diffusion transformers can produce high-quality samples that rival those of state-of-the-art generative models.\\n2. **Flexibility**: Diffusion transformers can be applied to various domains, including image, video, and text generation.\\n3. **Efficient sampling**: The diffusion process allows for efficient sampling, making it possible to generate new data samples quickly and effectively.\\n\\nOverall, diffusion transformers represent a promising direction in deep learning research, offering a powerful tool for generating high-quality data samples while leveraging the strengths of both diffusion models and transformer architectures.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5552640d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Compared to the standard transformer architecture, the diffusion transformer architecture has several key differences:\\n\\n1. **Diffusion-based encoder**: The diffusion transformer uses a diffusion-based encoder, which iteratively refines the input data by adding noise and then removing it, whereas the standard transformer encoder uses self-attention mechanisms to process the input data.\\n2. **Reverse process**: The diffusion transformer learns the reverse process of the diffusion model, which involves removing the noise that was added during the encoding process, whereas the standard transformer does not have a reverse process.\\n3. **Sequential refinement**: The diffusion transformer refines the input data sequentially, using the output from the previous step as the input for the next step, whereas the standard transformer processes the input data in parallel using self-attention mechanisms.\\n4. **Noise schedule**: The diffusion transformer uses a noise schedule to control the amount of noise added during the encoding process, whereas the standard transformer does not have a noise schedule.\\n5. **Generation process**: The diffusion transformer generates new data samples by iteratively refining the input data, whereas the standard transformer generates new data samples using a decoder that takes the output from the encoder as input.\\n\\nIn terms of specific architectural components, the diffusion transformer typically consists of:\\n\\n* A diffusion-based encoder, which consists of a series of noise-adding and noise-removing layers\\n* A transformer decoder, which consists of a series of self-attention and feed-forward layers\\n* A reverse process network, which learns the reverse process of the diffusion model\\n\\nIn contrast, the standard transformer architecture typically consists of:\\n\\n* A self-attention-based encoder, which consists of a series of self-attention and feed-forward layers\\n* A self-attention-based decoder, which consists of a series of self-attention and feed-forward layers\\n\\nOverall, the diffusion transformer architecture is designed to leverage the strengths of both diffusion models and transformer architectures, and has several key differences compared to the standard transformer architecture.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e83fcf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'd be happy to provide a more detailed explanation of diffusion transformers.\\n\\n**Diffusion Models**\\n\\nDiffusion models are a class of generative models that work by iteratively refining the input data through a process of adding noise and then removing it. This process is repeated multiple times, with the model learning to reverse the diffusion process to generate new data samples.\\n\\nThe diffusion process consists of two main steps:\\n\\n1. **Forward process**: The input data is gradually corrupted by adding noise, resulting in a sequence of increasingly noisy versions of the data.\\n2. **Reverse process**: The model learns to reverse the diffusion process by removing the noise, resulting in a generated sample that is similar to the original input data.\\n\\n**Transformer Models**\\n\\nTransformer models, on the other hand, are primarily used for natural language processing and are known for their ability to handle sequential data and capture long-range dependencies. They consist of an encoder and a decoder, both of which are composed of self-attention and feed-forward layers.\\n\\nThe transformer model works by:\\n\\n1. **Encoding**: The input data is passed through the encoder, which generates a continuous representation of the input sequence.\\n2. **Decoding**: The output from the encoder is passed through the decoder, which generates the final output sequence.\\n\\n**Diffusion Transformers**\\n\\nDiffusion transformers combine the strengths of diffusion models and transformer architectures. They work by using the diffusion process to generate new data samples, while leveraging the transformer architecture to handle complex sequential data.\\n\\nThe diffusion transformer architecture typically consists of three main components:\\n\\n1. **Diffusion-based encoder**: This component uses the diffusion process to generate a sequence of noisy versions of the input data.\\n2. **Transformer decoder**: This component uses the output from the diffusion-based encoder to generate the final output sequence.\\n3. **Reverse process network**: This component learns the reverse process of the diffusion model, allowing the model to generate new data samples by iteratively refining the input data.\\n\\n**How Diffusion Transformers Work**\\n\\nThe diffusion transformer works by iteratively refining the input data through the diffusion process, while using the transformer architecture to handle complex sequential data. The process can be summarized as follows:\\n\\n1. **Input**: The input data is passed through the diffusion-based encoder, which generates a sequence of noisy versions of the input data.\\n2. **Diffusion process**: The noisy versions of the input data are passed through the transformer decoder, which generates a sequence of output samples.\\n3. **Reverse process**: The output samples are passed through the reverse process network, which learns to reverse the diffusion process and generate new data samples.\\n4. **Output**: The final output sample is generated by iteratively refining the input data through the diffusion process and transformer architecture.\\n\\n**Benefits of Diffusion Transformers**\\n\\nThe diffusion transformer architecture offers several benefits, including:\\n\\n1. **Improved generation quality**: By iteratively refining the input data, diffusion transformers can produce high-quality samples that rival those of state-of-the-art generative models.\\n2. **Flexibility**: Diffusion transformers can be applied to various domains, including image, video, and text generation.\\n3. **Efficient sampling**: The diffusion process allows for efficient sampling, making it possible to generate new data samples quickly and effectively.\\n\\nOverall, diffusion transformers represent a promising direction in deep learning research, offering a powerful tool for generating high-quality data samples while leveraging the strengths of both diffusion models and transformer architectures.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e42778fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Executive Summary**\\n\\nThe AI revolution in India is transforming the country's economy, society, and industries at an unprecedented pace. With a growing pool of talented engineers, a thriving startup ecosystem, and a supportive government, India is emerging as a hub for AI innovation. This report provides an in-depth analysis of the current state of AI in India, its applications, challenges, and future prospects.\\n\\n**Introduction**\\n\\nArtificial Intelligence (AI) has been gaining momentum globally, and India is no exception. The country has made significant strides in adopting AI technologies, with a growing number of startups, research institutions, and corporates investing heavily in AI research and development. The Indian government has also launched several initiatives to promote AI adoption, including the establishment of the National Artificial Intelligence Mission (NAIM) and the creation of a task force on AI.\\n\\n**Current State of AI in India**\\n\\nThe AI ecosystem in India is thriving, with a large number of startups, research institutions, and corporates working on various AI-related projects. The country has a significant pool of talented engineers, with many Indian institutes of technology (IITs) and other engineering colleges offering courses in AI and machine learning.\\n\\nSome of the key areas where AI is being applied in India include:\\n\\n1. **Healthcare**: AI is being used to improve healthcare outcomes in India, with applications such as disease diagnosis, personalized medicine, and patient engagement.\\n2. **Finance**: AI is being used to improve financial inclusion, detect fraud, and enhance customer experience in the financial sector.\\n3. **Retail**: AI is being used to improve customer experience, optimize inventory management, and enhance supply chain management in the retail sector.\\n4. **Transportation**: AI is being used to improve traffic management, optimize routes, and enhance safety in the transportation sector.\\n5. **Agriculture**: AI is being used to improve crop yields, detect diseases, and optimize irrigation systems in the agriculture sector.\\n\\n**Startups and Research Institutions**\\n\\nIndia is home to a large number of AI startups, with many of them receiving funding from venture capital firms and angel investors. Some of the notable AI startups in India include:\\n\\n1. **Niramai**: A healthtech startup that uses AI to detect breast cancer.\\n2. **SigTuple**: A healthtech startup that uses AI to analyze medical images.\\n3. **Locus**: A logistics startup that uses AI to optimize routes and improve delivery efficiency.\\n4. **ZestMoney**: A fintech startup that uses AI to provide credit scoring and lending services.\\n5. **Vernacular.ai**: A startup that uses AI to provide voice-based interfaces for various applications.\\n\\nResearch institutions such as the Indian Institute of Technology (IIT), Indian Institute of Science (IISc), and Tata Institute of Fundamental Research (TIFR) are also playing a significant role in advancing AI research in India.\\n\\n**Challenges and Opportunities**\\n\\nDespite the significant progress made in AI adoption, there are several challenges that need to be addressed, including:\\n\\n1. **Data quality**: The quality of data in India is a significant concern, with many datasets being incomplete, inaccurate, or biased.\\n2. **Talent gap**: There is a significant shortage of skilled AI professionals in India, with many companies struggling to find talent.\\n3. **Infrastructure**: The infrastructure for AI adoption in India is still in the nascent stage, with many companies struggling to access high-quality computing resources and data storage facilities.\\n4. **Regulation**: There is a need for clearer regulations and guidelines on AI adoption in India, with many companies struggling to navigate the complex regulatory landscape.\\n\\n**Future Prospects**\\n\\nThe future of AI in India looks promising, with the country expected to become a hub for AI innovation in the coming years. Some of the key trends and opportunities that are expected to shape the AI landscape in India include:\\n\\n1. **Increased adoption**: AI is expected to become more widespread in India, with more companies adopting AI technologies to improve efficiency and competitiveness.\\n2. **Growing startup ecosystem**: The startup ecosystem in India is expected to continue to thrive, with more startups emerging in the AI space.\\n3. **Increased investment**: There is expected to be increased investment in AI research and development in India, with more companies and research institutions investing in AI initiatives.\\n4. **Government support**: The Indian government is expected to continue to provide support for AI adoption, with more initiatives and programs being launched to promote AI innovation.\\n\\n**Conclusion**\\n\\nThe AI revolution in India is transforming the country's economy, society, and industries at an unprecedented pace. With a growing pool of talented engineers, a thriving startup ecosystem, and a supportive government, India is emerging as a hub for AI innovation. While there are several challenges that need to be addressed, the future of AI in India looks promising, with the country expected to become a leader in AI adoption and innovation in the coming years.\\n\\n**Recommendations**\\n\\nBased on the analysis presented in this report, the following recommendations are made:\\n\\n1. **Invest in AI research and development**: Companies and research institutions should invest in AI research and development to stay ahead of the curve.\\n2. **Develop AI talent**: There is a need to develop more AI talent in India, with companies and institutions investing in training and upskilling programs.\\n3. **Improve data quality**: There is a need to improve data quality in India, with companies and institutions investing in data collection, processing, and storage infrastructure.\\n4. **Clear regulations**: There is a need for clearer regulations and guidelines on AI adoption in India, with the government providing more clarity on AI-related policies and laws.\\n\\nBy addressing these challenges and opportunities, India can unlock the full potential of AI and become a leader in AI adoption and innovation in the coming years.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(query4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "825ed21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We were discussing the topic of diffusion transformers and their architecture. You had asked me to explain the concept in more detail, and I had provided a detailed explanation of how diffusion transformers work, their components, and their benefits.\\n\\nTo continue the conversation, I'd like to ask: What specific aspect of diffusion transformers would you like to explore further? Are you interested in learning more about their applications, their comparison to other generative models, or something else?\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(query5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fb35911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_docs = memory_store.similarity_search(\"\", k=100)\n",
    "len(hist_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
