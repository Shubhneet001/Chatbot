{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85587291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b7d6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\genai_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_4540\\3823595349.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(retriever=memory_store.as_retriever())\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "memory_store = FAISS.from_texts([\"\"], embeddings)\n",
    "memory = VectorStoreRetrieverMemory(retriever=memory_store.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62cbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant.\n",
    "\n",
    "Conversation history (retrieved from memory):\n",
    "{history}\n",
    "\n",
    "User Query: {query}\n",
    "\n",
    "Take the context of history conversation if necessary, if not then answer the query as it is.\n",
    "Don't overexplain things.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a82238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'query'], input_types={}, partial_variables={}, template=\"\\nYou are a helpful assistant.\\n\\nConversation history (retrieved from memory):\\n{history}\\n\\nUser Query: {query}\\n\\nTake the context of history conversation if necessary, if not then answer the query as it is.\\nDon't overexplain things.\\n\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"history\", \"query\"]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed2c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f867d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(query: str):\n",
    "    history_docs = memory.load_memory_variables({'input':query})\n",
    "    return history_docs.get(\"history\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9941e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'history': RunnableLambda(get_history),\n",
    "    'query': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f330e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain = parallel_chain | prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str):\n",
    "    answer = main_chain.invoke(query)\n",
    "    memory.save_context({\"input\": query}, {\"output\": answer})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c942375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Diffusion transformers are a type of deep learning model that combines diffusion models with transformer architectures. They're mainly used for image and video generation tasks, like image synthesis and editing. The diffusion part helps with generating new data by iteratively refining noise, while the transformer part helps with understanding the context and structure of the data.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"can you explain me about the diffusion transformers in short?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Compared to the standard transformer architecture, diffusion transformers have an additional diffusion-based encoder and decoder. The standard transformer relies on self-attention mechanisms, whereas diffusion transformers combine this with a diffusion process that progressively refines the input noise to generate the output. This allows diffusion transformers to better handle image and video generation tasks.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"compare its architecture from the standard one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e83fcf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The AI revolution in India has witnessed significant growth in recent years, with the country emerging as a prominent player in the global AI landscape. Here's a detailed report:\\n\\n**Introduction**\\nThe AI revolution in India began to take shape in the early 2010s, with the government launching initiatives to promote AI research and development. Since then, the country has made tremendous progress, with AI being increasingly adopted across various sectors, including healthcare, finance, education, and transportation.\\n\\n**History and Milestones**\\nIndia's AI journey can be divided into three phases:\\n1. **Early beginnings (2010-2015)**: The government launched initiatives like the National e-Governance Plan and the Digital India program, which laid the foundation for AI adoption.\\n2. **Growth phase (2015-2020)**: The government launched the National AI Strategy, which outlined a roadmap for AI development in India. This phase saw significant investments in AI research and development, with the establishment of institutions like the NITI Aayog's AI Task Force.\\n3. **Accelerated growth (2020-present)**: The COVID-19 pandemic accelerated AI adoption in India, with the government launching initiatives like the AI for All program and the Responsible AI initiative.\\n\\n**Key Sectors and Applications**\\nAI is being increasingly adopted in various sectors in India, including:\\n1. **Healthcare**: AI-powered diagnostic tools, personalized medicine, and telemedicine platforms are transforming the healthcare landscape.\\n2. **Finance**: AI-powered chatbots, virtual assistants, and predictive analytics are being used to improve customer experience and risk management.\\n3. **Education**: AI-powered adaptive learning platforms, intelligent tutoring systems, and virtual classrooms are revolutionizing the education sector.\\n4. **Transportation**: AI-powered traffic management systems, autonomous vehicles, and smart mobility solutions are being developed to improve traffic flow and reduce congestion.\\n\\n**Challenges and Opportunities**\\nWhile India has made significant progress in AI, there are challenges that need to be addressed, including:\\n1. **Data quality and availability**: Access to high-quality data is essential for AI development, but India still lags behind in terms of data infrastructure.\\n2. **Talent and skills**: The demand for AI talent in India far exceeds the supply, with a significant shortage of skilled professionals.\\n3. **Regulatory framework**: A clear regulatory framework is needed to ensure responsible AI development and deployment.\\n\\n**Future Outlook**\\nThe future of AI in India looks promising, with the government planning to invest heavily in AI research and development. The country is expected to become a major AI hub, with startups and companies leveraging AI to drive innovation and growth. As AI continues to transform various sectors, it is essential for India to address the challenges and capitalize on the opportunities to become a leader in the global AI landscape.\\n\\nNote: The conversation history about diffusion transformers is not directly relevant to this query, but it highlights the growing interest in AI and its applications in India.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"Generate a detailed report on AI revolution in India.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ed21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
